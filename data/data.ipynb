{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16c4497a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset Loaded Successfully\n",
      "Dataset Shape: (2520751, 53)\n",
      "\n",
      "Detected Label Column: Attack Type\n",
      "\n",
      "Available Labels:\n",
      "['normal traffic' 'port scanning' 'web attacks' 'brute force' 'ddos'\n",
      " 'bots' 'dos']\n",
      "\n",
      "Label Distribution:\n",
      "Attack Type\n",
      "0    2095057\n",
      "1     425694\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cleaning data...\n",
      "After cleaning shape: (2520751, 53)\n",
      "\n",
      "Scaling features...\n",
      "Normal samples found: 2095057\n",
      "\n",
      "Training Isolation Forest Model...\n",
      "Model Training Completed\n",
      "\n",
      "Running predictions...\n",
      "\n",
      "Model Performance Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93    418697\n",
      "           1       0.73      0.39      0.51     85454\n",
      "\n",
      "    accuracy                           0.87    504151\n",
      "   macro avg       0.81      0.68      0.72    504151\n",
      "weighted avg       0.86      0.87      0.86    504151\n",
      "\n",
      "\n",
      "Model and scaler saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# SELF LEARNING CYBER ATTACK DETECTION BOT\n",
    "# FINAL TRAINING CODE (CICIDS DATASET)\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# ============================================\n",
    "# 1. LOAD DATASET\n",
    "# ============================================\n",
    "\n",
    "file_path = r'E:/Projects/ML/KSR/data/CICD2017.csv'\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Dataset Loaded Successfully\")\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "\n",
    "# ============================================\n",
    "# 2. AUTO DETECT LABEL COLUMN\n",
    "# ============================================\n",
    "\n",
    "possible_labels = ['label', 'attack', 'attack type', 'class']\n",
    "\n",
    "label_col = None\n",
    "for col in df.columns:\n",
    "    if col.strip().lower() in possible_labels:\n",
    "        label_col = col\n",
    "        break\n",
    "\n",
    "# if not found, assume last column\n",
    "if label_col is None:\n",
    "    label_col = df.columns[-1]\n",
    "\n",
    "print(\"\\nDetected Label Column:\", label_col)\n",
    "\n",
    "# ============================================\n",
    "# 3. CLEAN LABEL VALUES\n",
    "# ============================================\n",
    "\n",
    "df[label_col] = df[label_col].astype(str)\n",
    "df[label_col] = df[label_col].str.strip()\n",
    "df[label_col] = df[label_col].str.lower()\n",
    "\n",
    "print(\"\\nAvailable Labels:\")\n",
    "print(df[label_col].unique())\n",
    "\n",
    "# Convert labels safely\n",
    "# benign / normal → 0\n",
    "# attack → 1\n",
    "normal_keywords = ['benign', 'normal']\n",
    "\n",
    "df[label_col] = df[label_col].apply(\n",
    "    lambda x: 0 if any(k in x for k in normal_keywords) else 1\n",
    ")\n",
    "\n",
    "print(\"\\nLabel Distribution:\")\n",
    "print(df[label_col].value_counts())\n",
    "\n",
    "# ============================================\n",
    "# 4. REMOVE INVALID VALUES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nCleaning data...\")\n",
    "\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print(\"After cleaning shape:\", df.shape)\n",
    "\n",
    "# ============================================\n",
    "# 5. SPLIT FEATURES & LABEL\n",
    "# ============================================\n",
    "\n",
    "X = df.drop(label_col, axis=1)\n",
    "y = df[label_col]\n",
    "\n",
    "# ============================================\n",
    "# 6. NORMALIZATION\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nScaling features...\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ============================================\n",
    "# 7. TRAIN ONLY NORMAL TRAFFIC\n",
    "# ============================================\n",
    "\n",
    "X_normal = X_scaled[y == 0]\n",
    "\n",
    "print(\"Normal samples found:\", len(X_normal))\n",
    "\n",
    "if len(X_normal) == 0:\n",
    "    raise ValueError(\n",
    "        \"No BENIGN/NORMAL samples found. \"\n",
    "        \"This file may contain only attack traffic. \"\n",
    "        \"Use a dataset containing normal traffic also.\"\n",
    "    )\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# 8. TRAIN ISOLATION FOREST MODEL\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nTraining Isolation Forest Model...\")\n",
    "\n",
    "model = IsolationForest(\n",
    "    n_estimators=120,\n",
    "    contamination=0.03,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_normal)\n",
    "\n",
    "print(\"Model Training Completed\")\n",
    "\n",
    "# ============================================\n",
    "# 9. PREDICTION\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nRunning predictions...\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# convert output\n",
    "y_pred = np.where(y_pred == -1, 1, 0)\n",
    "\n",
    "# ============================================\n",
    "# 10. MODEL EVALUATION\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nModel Performance Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ============================================\n",
    "# 11. SAVE MODEL & SCALER\n",
    "# ============================================\n",
    "\n",
    "joblib.dump(model, \"anomaly_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"\\nModel and scaler saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
